# Prometheus Stack Helm Values for Multi-Tenant Platform
# Configures Prometheus with tenant-aware scraping and metrics isolation
---
# kube-prometheus-stack values
# Chart: prometheus-community/kube-prometheus-stack

# Global settings
fullnameOverride: prometheus

# Prometheus configuration
prometheus:
  enabled: true

  prometheusSpec:
    # Retention
    retention: 30d
    retentionSize: "50GB"

    # Resource limits
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 8Gi

    # Storage
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi

    # Security context
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
      fsGroup: 65534

    # Pod anti-affinity for HA
    podAntiAffinity: hard

    # Replicas for HA
    replicas: 2

    # Service monitor selector - scrape all ServiceMonitors with platform label
    serviceMonitorSelector:
      matchExpressions:
        - key: platform.devsecops.io/monitoring
          operator: In
          values:
            - enabled

    # Pod monitor selector
    podMonitorSelector:
      matchExpressions:
        - key: platform.devsecops.io/monitoring
          operator: In
          values:
            - enabled

    # Probe selector
    probeSelector:
      matchExpressions:
        - key: platform.devsecops.io/monitoring
          operator: In
          values:
            - enabled

    # Additional scrape configs for tenant namespaces
    additionalScrapeConfigs:
      # Scrape all pods with prometheus.io annotations in tenant namespaces
      - job_name: 'tenant-pods'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names: []  # Will be populated dynamically
        relabel_configs:
          # Only scrape pods with prometheus.io/scrape annotation
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          # Use custom path if specified
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          # Use custom port if specified
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          # Add tenant label from namespace
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: tenant
            regex: ^([^-]+)-.*$
            replacement: $1
          # Add namespace label
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          # Add pod label
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          # Add container label
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: replace
            target_label: container

    # External labels for federation
    externalLabels:
      cluster: production
      platform: multi-tenant-devsecops

    # Remote write for long-term storage (optional)
    # remoteWrite:
    #   - url: http://thanos-receive:19291/api/v1/receive

  # Ingress for Prometheus UI (platform admins only)
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Prometheus - Platform Admins"
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - prometheus.platform.example.com
    tls:
      - secretName: prometheus-tls
        hosts:
          - prometheus.platform.example.com

# Alertmanager configuration
alertmanager:
  enabled: true

  alertmanagerSpec:
    replicas: 3
    retention: 120h

    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi

    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    # Pod anti-affinity
    podAntiAffinity: hard

  # Alertmanager config will be in separate file
  config:
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'tenant', 'namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'platform-default'

      routes:
        # Route tenant alerts to their channels
        - match_re:
            tenant: '.+'
          receiver: 'tenant-alerts'
          group_by: ['alertname', 'tenant']
          continue: true

        # Critical alerts go to platform team
        - match:
            severity: critical
          receiver: 'platform-critical'

    receivers:
      - name: 'platform-default'
        webhook_configs:
          - url: 'http://alertmanager-webhook:8080/webhook'

      - name: 'platform-critical'
        pagerduty_configs:
          - service_key_file: /etc/alertmanager/secrets/pagerduty-key

      - name: 'tenant-alerts'
        webhook_configs:
          - url: 'http://tenant-alert-router:8080/route'
            send_resolved: true

  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: alertmanager-basic-auth
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - alertmanager.platform.example.com
    tls:
      - secretName: alertmanager-tls
        hosts:
          - alertmanager.platform.example.com

# Grafana configuration
grafana:
  enabled: true

  replicas: 2

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # Admin password from secret
  admin:
    existingSecret: grafana-admin-secret
    userKey: admin-user
    passwordKey: admin-password

  # Persistence
  persistence:
    enabled: true
    storageClassName: standard
    size: 10Gi

  # Grafana.ini configuration
  grafana.ini:
    server:
      root_url: https://grafana.platform.example.com
    security:
      disable_gravatar: true
    users:
      auto_assign_org: true
      auto_assign_org_role: Viewer
    auth:
      disable_login_form: false
    auth.generic_oauth:
      enabled: true
      name: "Platform SSO"
      allow_sign_up: true
      scopes: openid profile email groups
      auth_url: https://sso.platform.example.com/oauth/authorize
      token_url: https://sso.platform.example.com/oauth/token
      api_url: https://sso.platform.example.com/userinfo
      role_attribute_path: "contains(groups[*], 'platform-admins') && 'Admin' || contains(groups[*], 'platform-operators') && 'Editor' || 'Viewer'"

  # Data sources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-prometheus:9090
          access: proxy
          isDefault: true
          jsonData:
            timeInterval: "15s"

        - name: Loki
          type: loki
          url: http://loki:3100
          access: proxy
          jsonData:
            maxLines: 1000

        - name: Alertmanager
          type: alertmanager
          url: http://prometheus-alertmanager:9093
          access: proxy
          jsonData:
            implementation: prometheus

  # Dashboard providers
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'platform'
          orgId: 1
          folder: 'Platform'
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/platform

        - name: 'tenants'
          orgId: 1
          folder: 'Tenants'
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/tenants

  # Sidecar for dashboard loading
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      searchNamespace: ALL
      folderAnnotation: grafana_folder

  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - grafana.platform.example.com
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.platform.example.com

# Node exporter for node metrics
nodeExporter:
  enabled: true

# Kube state metrics
kubeStateMetrics:
  enabled: true

# Default rules
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

# Additional PrometheusRules
additionalPrometheusRulesMap:
  tenant-alerts:
    groups:
      - name: tenant-resource-alerts
        rules:
          - alert: TenantHighCPUUsage
            expr: |
              sum by (tenant, namespace) (
                rate(container_cpu_usage_seconds_total{namespace=~".*-dev|.*-staging|.*-prod"}[5m])
              ) / sum by (tenant, namespace) (
                kube_resourcequota{resource="limits.cpu", type="hard"}
              ) > 0.8
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Tenant {{ $labels.tenant }} high CPU usage"
              description: "Namespace {{ $labels.namespace }} is using more than 80% of CPU quota"

          - alert: TenantHighMemoryUsage
            expr: |
              sum by (tenant, namespace) (
                container_memory_working_set_bytes{namespace=~".*-dev|.*-staging|.*-prod"}
              ) / sum by (tenant, namespace) (
                kube_resourcequota{resource="limits.memory", type="hard"}
              ) > 0.8
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Tenant {{ $labels.tenant }} high memory usage"
              description: "Namespace {{ $labels.namespace }} is using more than 80% of memory quota"

          - alert: TenantPodCrashLooping
            expr: |
              rate(kube_pod_container_status_restarts_total{namespace=~".*-dev|.*-staging|.*-prod"}[15m]) * 60 * 15 > 5
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Pod crash looping in tenant {{ $labels.tenant }}"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has restarted more than 5 times in 15 minutes"

          - alert: TenantPodNotReady
            expr: |
              sum by (tenant, namespace, pod) (
                kube_pod_status_phase{phase!="Running", phase!="Succeeded", namespace=~".*-dev|.*-staging|.*-prod"}
              ) > 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: "Pod not ready in tenant {{ $labels.tenant }}"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been in non-running state for 15 minutes"
